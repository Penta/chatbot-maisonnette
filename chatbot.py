import os
import base64
import logging
import re
from io import BytesIO
import discord
from dotenv import load_dotenv
from PIL import Image
import emoji
import tiktoken
from openai import AsyncOpenAI, OpenAIError
import json

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()
DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
DISCORD_CHANNEL_ID = os.getenv('DISCORD_CHANNEL_ID')
PERSONALITY_PROMPT_FILE = os.getenv('PERSONALITY_PROMPT_FILE', 'personality_prompt.txt')
CONVERSATION_HISTORY_FILE = os.getenv('CONVERSATION_HISTORY_FILE', 'conversation_history.json')

# Initialiser le client OpenAI asynchrone ici
openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

BOT_VERSION = "2.3.0"

# V√©rifier que les tokens et le prompt de personnalit√© sont r√©cup√©r√©s
if DISCORD_TOKEN is None or OPENAI_API_KEY is None or DISCORD_CHANNEL_ID is None:
    raise ValueError("Les tokens ou l'ID du canal ne sont pas d√©finis dans les variables d'environnement.")

if not os.path.isfile(PERSONALITY_PROMPT_FILE):
    raise FileNotFoundError(f"Le fichier de prompt de personnalit√© '{PERSONALITY_PROMPT_FILE}' est introuvable.")

# Lire le prompt de personnalit√© depuis le fichier
with open(PERSONALITY_PROMPT_FILE, 'r', encoding='utf-8') as f:
    PERSONALITY_PROMPT = f.read().strip()

# Log configuration
log_format = '%(asctime)-13s : %(name)-15s : %(levelname)-8s : %(message)s'
logging.basicConfig(handlers=[logging.FileHandler("./chatbot.log", 'a', 'utf-8')], format=log_format, level="INFO")

console = logging.StreamHandler()
console.setLevel(logging.INFO)
console.setFormatter(logging.Formatter(log_format))

logger = logging.getLogger("chatbot")
logger.setLevel("INFO")

logging.getLogger('').addHandler(console)

httpx_logger = logging.getLogger('httpx')
httpx_logger.setLevel(logging.WARNING)

# Initialiser les intents
intents = discord.Intents.default()
intents.message_content = True  # Activer l'intent pour les contenus de message

# Liste pour stocker l'historique des conversations
conversation_history = []

def load_conversation_history():
    global conversation_history
    if os.path.isfile(CONVERSATION_HISTORY_FILE):
        try:
            with open(CONVERSATION_HISTORY_FILE, 'r', encoding='utf-8') as f:
                loaded_history = json.load(f)
                # Exclure uniquement le PERSONALITY_PROMPT
                conversation_history = [
                    msg for msg in loaded_history
                    if not (msg.get("role") == "system" and msg.get("content") == PERSONALITY_PROMPT)
                ]
            logger.info(f"Historique charg√© depuis {CONVERSATION_HISTORY_FILE}")
        except Exception as e:
            logger.error(f"Erreur lors du chargement de l'historique : {e}")
            conversation_history = []
    else:
        logger.info(f"Aucun fichier d'historique trouv√©. Un nouveau fichier sera cr√©√© √† {CONVERSATION_HISTORY_FILE}")

def has_text(text):
    """
    D√©termine si le texte fourni est non vide apr√®s suppression des espaces.
    """
    return bool(text.strip())

# Fonction de sauvegarde de l'historique
def save_conversation_history():
    try:
        with open(CONVERSATION_HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=4)
    except Exception as e:
        logger.error(f"Erreur lors de la sauvegarde de l'historique : {e}")

# Charger l'encodeur pour le mod√®le GPT-4o mini
encoding = tiktoken.get_encoding("o200k_base")

# Convertir l'ID du channel en entier
try:
    chatgpt_channel_id = int(DISCORD_CHANNEL_ID)
except ValueError:
    raise ValueError("L'ID du channel Discord est invalide. Assurez-vous qu'il s'agit d'un entier.")

class MyDiscordClient(discord.Client):
    async def close(self):
        global openai_client
        if openai_client is not None:
            await openai_client.close()
            openai_client = None
        await super().close()

# Initialiser le client Discord avec les intents modifi√©s
client_discord = MyDiscordClient(intents=intents)

# Appeler la fonction pour charger l'historique au d√©marrage
load_conversation_history()

def resize_image(image_bytes, mode='high', attachment_filename=None):
    try:
        with Image.open(BytesIO(image_bytes)) as img:
            original_format = img.format  # Store the original format

            if mode == 'high':
                # Redimensionner pour le mode haute fid√©lit√©
                img.thumbnail((2000, 2000))
                if min(img.size) < 768:
                    scale = 768 / min(img.size)
                    new_size = tuple(int(x * scale) for x in img.size)
                    img = img.resize(new_size, Image.Resampling.LANCZOS)
            elif mode == 'low':
                # Redimensionner pour le mode basse fid√©lit√©
                img = img.resize((512, 512))

            buffer = BytesIO()

            img_format = img.format
            if not img_format:
                if attachment_filename:
                    _, ext = os.path.splitext(attachment_filename)
                    ext = ext.lower()
                    format_mapping = {
                        '.jpg': 'JPEG',
                        '.jpeg': 'JPEG',
                        '.png': 'PNG',
                        '.gif': 'GIF',
                        '.bmp': 'BMP',
                        '.tiff': 'TIFF'
                    }
                    img_format = format_mapping.get(ext, 'PNG')
                else:
                    img_format = 'PNG'

            img.save(buffer, format=img_format)
            return buffer.getvalue()
    except Exception as e:
        logger.error(f"Error resizing image: {e}")
        raise

def extract_text_from_message(message):
    content = message.get("content", "")
    if isinstance(content, list):
        # Extraire le texte de chaque √©l√©ment de la liste
        texts = []
        for part in content:
            if isinstance(part, dict):
                text = part.get("text", "")
                if text:
                    texts.append(text)
        return ' '.join(texts)
    elif isinstance(content, str):
        return content
    else:
        return ""

def calculate_cost(usage, model='gpt-4o-mini'):
    input_tokens = usage.get('prompt_tokens', 0)
    output_tokens = usage.get('completion_tokens', 0)

    # D√©finir les tarifs par mod√®le
    model_costs = {
        'gpt-4o': {
            'input_rate': 5.00 / 1_000_000,    # 5$ pour 1M tokens d'entr√©e
            'output_rate': 15.00 / 1_000_000  # 15$ pour 1M tokens de sortie
        },
        'gpt-4o-mini': {
            'input_rate': 0.150 / 1_000_000,   # 0.150$ pour 1M tokens d'entr√©e
            'output_rate': 0.600 / 1_000_000   # 0.600$ pour 1M tokens de sortie
        }
    }

    # Obtenir les tarifs du mod√®le sp√©cifi√©
    if model not in model_costs:
        logger.warning(f"Mod√®le inconnu '{model}'. Utilisation des tarifs par d√©faut pour 'gpt-4o-mini'.")
        model = 'gpt-4o-mini'

    input_rate = model_costs[model]['input_rate']
    output_rate = model_costs[model]['output_rate']

    # Calculer les co√ªts
    input_cost = input_tokens * input_rate
    output_cost = output_tokens * output_rate
    total_cost = input_cost + output_cost

    return input_tokens, output_tokens, total_cost

def is_relevant_message(message):
    content = message["content"]

    if isinstance(content, list):
        content = ''.join(part.get('text', '') for part in content if 'text' in part)

    if len(content.strip()) < 5:
        return False

    discord_emoji_pattern = r'<a?:\w+:\d+>'

    def is_discord_emoji(part):
        return bool(re.fullmatch(discord_emoji_pattern, part))

    tokens = re.split(discord_emoji_pattern, content)
    emojis_only = True
    standard_emojis = [char for char in content if emoji.is_emoji(char)]
    discord_emojis = re.findall(discord_emoji_pattern, content)

    text_without_emojis = re.sub(discord_emoji_pattern, '', content)
    for char in text_without_emojis:
        if not char.isspace() and not emoji.is_emoji(char):
            emojis_only = False
            break

    if len(standard_emojis) + len(discord_emojis) == 0:
        emojis_only = False

    if emojis_only and len(content.strip()) > 0:
        return False

    return True

async def summarize_conversation(messages_to_summarize):
    try:
        # Pr√©parer le prompt pour la synth√®se
        prompt = "Synth√©tise les messages suivants en un r√©sum√© concis de maximum 1000 tokens :\n"
        for msg in messages_to_summarize:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            prompt += f"{role.capitalize()}: {content}\n"

        # Appel √† l'API OpenAI pour g√©n√©rer la synth√®se
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Tu es un assistant utile qui r√©sume les conversations."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1000,
            temperature=0.5
        )

        if response and response.choices:
            summary = response.choices[0].message.content.strip()
            logger.info("Synth√®se g√©n√©r√©e avec succ√®s.")

            # Calcul et log du co√ªt de la synth√®se
            if hasattr(response, 'usage') and response.usage:
                usage = {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens
                }
                input_tokens, output_tokens, total_cost = calculate_cost(usage, model='gpt-4o-mini')
                logger.info(
                    f"Co√ªt : ${total_cost:.6f}, Input Tokens: {input_tokens}, Output Tokens: {output_tokens}."
                )
            else:
                logger.warning("Informations d'utilisation non disponibles pour le calcul du co√ªt de la synth√®se.")

            return summary
        else:
            logger.error("Aucune r√©ponse re√ßue lors de la synth√®se.")
            return None

    except OpenAIError as e:
        logger.error(f"Erreur lors de la synth√®se : {e}")
        return None

async def call_gpt4o_for_image_analysis(image_data, user_text=None, detail='high'):
    try:
        # Pr√©parer la requ√™te pour GPT-4o
        if user_text:
            prompt = (
                f"Analyse cette image de mani√®re extr√™mement pr√©cise en tenant compte de la description suivante : \"{user_text}\"."
                "Si des personnages sont pr√©sents, d√©cris avec d√©tails leurs v√™tements, accessoires et physique."
                "D√©cris leurs courbes, leur taille, leur poids, leurs mensurations."
                "D√©cris comment ils int√©ragissent avec leur environnement et avec les autres personnages."
        )
        else:
            prompt = (
                "Analyse cette image de mani√®re extr√™mement pr√©cise s'il te pla√Æt."
                "Si des personnages sont pr√©sents, d√©cris avec d√©tails leurs v√™tements, accessoires et physique."
                "D√©cris leurs courbes, leur taille, leur poids, leurs mensurations."
                "D√©cris comment ils int√©ragissent avec leur environnement et avec les autres personnages."
            )

        message_to_send = {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt},   
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}",
                        "detail": detail
                    }
                }
            ]
        }

        # Appel √† GPT-4o
        response = await openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[message_to_send],
            max_tokens=4096
        )

        if response:
            analysis = response.choices[0].message.content
            logging.info(f"Analyse de l'image par GPT-4o : {analysis}")

            # Calcul et affichage du co√ªt
            if hasattr(response, 'usage') and response.usage:
                usage = {
                    'prompt_tokens': response.usage.prompt_tokens,
                    'completion_tokens': response.usage.completion_tokens
                }
                input_tokens, output_tokens, total_cost = calculate_cost(usage, model='gpt-4o')
                logging.info(f"Co√ªt de l'analyse de l'image : ${total_cost:.4f} / Input: {input_tokens} / Output: {output_tokens}")
            else:
                logging.warning("Informations d'utilisation non disponibles pour le calcul du co√ªt.")

            return analysis
        else:
            return None 

    except OpenAIError as e:
        logger.error(f"Erreur lors de l'analyse de l'image avec GPT-4o: {e}")
        return None

async def call_gpt4o_mini_with_analysis(analysis_text, user_name, user_question, has_text):
    try:
        # Pr√©parer le message avec le prompt de personnalit√© et l'historique
        prompt_personality = {"role": "system", "content": PERSONALITY_PROMPT}

        # Pr√©parer le contexte de l'analyse
        analysis_message = {
            "role": "system",
            "content": (
                f"L'analyse de l'image fournie est la suivante :\n{analysis_text}\n\n"
            )
        }

        if has_text:
            # Pr√©parer le message utilisateur avec le texte
            user_message = {
                "role": "user",
                "content": (
                    f"{user_name} a √©crit : '{user_question}'.\n"
                    "R√©ponds en te basant uniquement sur l'analyse fournie.\
                    Mais ne mentionne pas que tu viens de lire une analyse pr√©-existante de l'image.\
                    Fais comme si c'est toi qui as analys√© l'image."
                )
            }
        else:
            # Pr√©parer une instruction pour commenter l'image
            user_message = {
                "role": "user",
                "content": (
                    f"{user_name} a partag√© une image sans texte additionnel.\n"
                    "Commente globalement l'image en te basant sur l'analyse fournie.\
                    R√©agis comme quelqu'un avec ta personnalit√© r√©agirait ! Ne fais pas juste un b√™te commentaire comme un robot.\
                    Mais ne mentionne pas que tu viens de lire une analyse pr√©-existante de l'image.\
                    Fais comme si c'est toi qui as analys√© l'image."
                )
            }

        # Assembler les messages avec le prompt de personnalit√© en premier
        messages = [
            {"role": "system", "content": PERSONALITY_PROMPT},
            analysis_message
        ] + conversation_history + [user_message]

        # Appel √† GPT-4o Mini pour r√©agir √† la question et √† l'analyse
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=450
        )

        if response:
            reply = response.choices[0].message.content
            logging.info(f"R√©ponse de GPT-4o Mini : {reply}")
            return reply
        else:
            return None

    except OpenAIError as e:
        logger.error(f"Erreur lors de la g√©n√©ration de r√©ponse avec GPT-4o Mini: {e}")
        return None

async def read_text_file(attachment):
    file_bytes = await attachment.read()
    return file_bytes.decode('utf-8')

async def encode_image_from_attachment(attachment, mode='high'):
    image_data = await attachment.read()
    resized_image = resize_image(image_data, mode=mode, attachment_filename=attachment.filename)
    return base64.b64encode(resized_image).decode('utf-8')

async def call_openai_api(user_text, user_name, image_data=None, detail='high'):

    # Pr√©parer le contenu pour l'appel API
    message_to_send = {
        "role": "user",
        "content": [
            {"type": "text", "text": f"{user_name} dit : {user_text}"}
        ]
    }

    # Inclure l'image dans l'appel API courant
    if image_data:
        message_to_send["content"].append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{image_data}",
                "detail": detail
            }
        })

    # Assembler les messages avec le prompt de personnalit√© en premier
    messages = [
        {"role": "system", "content": PERSONALITY_PROMPT}
    ] + conversation_history + [message_to_send]

    try:
        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=400,
            temperature=1.0
        )

        if response:
            reply = response.choices[0].message.content

        # Ajouter le message de l'utilisateur √† l'historique global, mais uniquement s'il ne s'agit pas d'une image
        if image_data is None:
            await add_to_conversation_history(message_to_send)

        # Ajouter la r√©ponse de l'IA directement √† l'historique
        await add_to_conversation_history({
            "role": "assistant",
            "content": reply
        })

        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            input_tokens, output_tokens, total_cost = calculate_cost({
                'prompt_tokens': usage.prompt_tokens,
                'completion_tokens': usage.completion_tokens
            })

        # Afficher dans la console
        logging.info(f"Co√ªt de la r√©ponse : ${total_cost:.4f} / Input: {input_tokens} / Output: {output_tokens} / Total: {input_tokens + output_tokens}")

        return response
    except OpenAIError as e:
        logger.error(f"Error calling OpenAI API: {e}")
    except Exception as e:
        logger.error(f"Error calling OpenAI API: {e}")
    return None

@client_discord.event
async def on_ready():
    logger.info(f'Bot connect√© en tant que {client_discord.user}')

    if not conversation_history:
        logger.info("Aucun historique trouv√©. L'historique commence vide.")

    # Envoyer un message de version dans le canal Discord
    channel = client_discord.get_channel(chatgpt_channel_id)
    if channel:
        try:
            embed = discord.Embed(
                title="Bot D√©marr√©",
                description=f"üéâ Le ChatBot est en ligne ! Version {BOT_VERSION}",
                color=0x00ff00  # Vert
            )
            await channel.send(embed=embed)
            logger.info(f"Message de connexion envoy√© dans le canal ID {chatgpt_channel_id}")
        except discord.Forbidden:
            logger.error(f"Permissions insuffisantes pour envoyer des messages dans le canal ID {chatgpt_channel_id}.")
        except discord.HTTPException as e:
            logger.error(f"Erreur lors de l'envoi du message de connexion : {e}")
    else:
        logger.error(f"Canal avec ID {chatgpt_channel_id} non trouv√©.")

@client_discord.event
async def on_message(message):
    global conversation_history

    # V√©rifier si le message provient du canal autoris√©
    if message.channel.id != chatgpt_channel_id:
        return

    # Ignorer les messages du bot lui-m√™me
    if message.author == client_discord.user:
        return

    user_text = message.content.strip()
    image_data = None
    file_content = None
    attachment_filename = None

    # V√©rifier si le message est la commande de r√©initialisation
    if user_text.lower() == "!reset_history":
        # V√©rifier si l'utilisateur a les permissions administratives
        if not message.author.guild_permissions.administrator:
            await message.channel.send("‚ùå Vous n'avez pas la permission d'utiliser cette commande.")
            return

        conversation_history = []
        save_conversation_history()
        await message.channel.send("‚úÖ L'historique des conversations a √©t√© r√©initialis√©.")
        logger.info(f"Historique des conversations r√©initialis√© par {message.author}.")
        return  # Arr√™ter le traitement du message apr√®s la r√©initialisation

    # Extensions de fichiers autoris√©es
    allowed_extensions = ['.txt', '.py', '.html', '.css', '.js']

    # Variables pour stocker si le message contient une image et/ou un fichier
    has_image = False
    has_file = False

    # V√©rifier s'il y a une pi√®ce jointe
    if message.attachments:
        for attachment in message.attachments:
            # V√©rifier si c'est un fichier avec une extension autoris√©e
            if any(attachment.filename.endswith(ext) for ext in allowed_extensions):
                file_content = await read_text_file(attachment)
                attachment_filename = attachment.filename
                break
            # V√©rifier si c'est une image
            elif attachment.content_type in ['image/jpeg', 'image/png', 'image/gif', 'image/bmp', 'image/tiff']:
                image_data = await encode_image_from_attachment(attachment, mode='high')
                break

    # Si une image est pr√©sente, la traiter
    if image_data:
        has_user_text = has_text(user_text)
        user_text_to_use = user_text if has_user_text else None

        # √âtape 1 : GPT-4o analyse l'image, potentiellement guid√©e par le texte de l'utilisateur
        analysis = await call_gpt4o_for_image_analysis(image_data, user_text=user_text_to_use)

        if analysis:

            # **Ajouter l'analyse √† l'historique avant de r√©agir avec GPT-4o Mini**
            analysis_message = {
                "role": "system",
                "content": f"Analyse de l'image : {analysis}"
            }
            await add_to_conversation_history(analysis_message)

            # √âtape 2 : GPT-4o Mini r√©agit √† la question et √† l'analyse
            reply = await call_gpt4o_mini_with_analysis(analysis, message.author.name, user_text, has_user_text)
            if reply:
                await message.channel.send(reply)

                # **Ajout des messages √† l'historique**
                # Cr√©er un message utilisateur modifi√© indiquant qu'une image a √©t√© post√©e
                if has_user_text:
                    user_message_content = f"{user_text} (a post√© une image.)"
                else:
                    user_message_content = (
                        "Une image a √©t√© post√©e, mais elle n'est pas disponible pour analyse directe. "
                        "Veuillez vous baser uniquement sur l'analyse fournie."
                    )

                user_message = {
                    "role": "user",
                    "content": user_message_content
                }

                # Ajouter le message utilisateur √† l'historique
                await add_to_conversation_history(user_message)

                # Cr√©er le message assistant avec la r√©ponse de GPT-4o Mini
                assistant_message = {
                    "role": "assistant",
                    "content": reply
                }

                # Ajouter le message assistant √† l'historique
                await add_to_conversation_history(assistant_message)
            else:
                await message.channel.send("D√©sol√©, je n'ai pas pu g√©n√©rer une r√©ponse.")
        else:
            await message.channel.send("D√©sol√©, je n'ai pas pu analyser l'image.")
        # Apr√®s traitement de l'image, ne pas continuer
        return

    # Ajouter le contenu du fichier √† la requ√™te si pr√©sent
    if file_content:
        user_text += f"\nContenu du fichier {attachment.filename}:\n{file_content}"

    # V√©rifier si le texte n'est pas vide apr√®s ajout du contenu du fichier
    if not has_text(user_text):
        return  # Ne pas appeler l'API si le texte est vide

    # Appeler l'API OpenAI
    result = await call_openai_api(user_text, message.author.name, image_data)
    if result:
        reply = result.choices[0].message.content
        await message.channel.send(reply)

async def add_to_conversation_history(new_message):
    global conversation_history

    # Ne pas ajouter le PERSONALITY_PROMPT √† l'historique
    if new_message.get("role") == "system" and new_message.get("content") == PERSONALITY_PROMPT:
        logger.debug("PERSONALITY_PROMPT syst√®me non ajout√© √† l'historique.")
        return

    # Filtrer les messages pertinents pour l'historique
    if is_relevant_message(new_message):
        # Ajouter le message √† l'historique
        conversation_history.append(new_message)
        save_conversation_history()
        logger.debug(f"Message ajout√© √† l'historique. Taille actuelle : {len(conversation_history)}")

        # V√©rifier si la limite de 150 messages est atteinte
        if len(conversation_history) > 150:
            logger.info("Limite de 150 messages atteinte. D√©marrage de la synth√®se des messages les plus anciens.")
            
            # Extraire les 50 messages les plus anciens pour la synth√®se
            messages_to_summarize = conversation_history[:50]
            
            # G√©n√©rer la synth√®se
            summary = await summarize_conversation(messages_to_summarize)
            
            if summary:
                # Cr√©er un message de synth√®se
                summary_message = {
                    "role": "system",
                    "content": f"Synth√®se des pr√©c√©dents messages : {summary}"
                }
                
                # Remplacer les 50 premiers messages par la synth√®se
                conversation_history = [summary_message] + conversation_history[50:]
                save_conversation_history()
                logger.info("Synth√®se ajout√©e √† l'historique et les 50 anciens messages ont √©t√© supprim√©s.")
            else:
                logger.error("√âchec de la g√©n√©ration de la synth√®se. L'historique n'a pas √©t√© modifi√©.")


# D√©marrer le bot Discord
client_discord.run(DISCORD_TOKEN)
